{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "114\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import string\n",
    "from os import listdir\n",
    "snippetFolder = \"/home/abc/ADM/Train_Data\"\n",
    "testSnippetFolder = \"/home/abc/ADM/Test_Data\"\n",
    "folder_list = [f for f in listdir(snippetFolder)]\n",
    "#print(folder_list)\n",
    "\n",
    "puncs = string.punctuation\n",
    "print(puncs)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for folder in folder_list:\n",
    "    #print(folder)\n",
    "    files_list = [f for f in listdir(snippetFolder + \"/\" + folder)]\n",
    "    #print(files_list)\n",
    "    #print(\"\\n\")\n",
    "    for file in files_list:\n",
    "        filePath = snippetFolder + \"/\" + folder + \"/\" + file\n",
    "        #print(\"File Path : \", filePath)\n",
    "        f = open(filePath,'r',encoding='utf-8')\n",
    "        data = f.readlines()\n",
    "        #print(\"Data : \", data)\n",
    "        #for d in data:\n",
    "        #    d.replace(\"\\n\",\"\")\n",
    "        textSnippet = ''.join(data)\n",
    "        #print(\"Text : \",textSnippet)\n",
    "        textSnippet = textSnippet.replace(\"\\n\",\"\")\n",
    "        #textSnippet = textSnippet.replace('\"',\"\")\n",
    "        \n",
    "        for p in puncs:\n",
    "            #print(p)\n",
    "            if p in textSnippet:\n",
    "                #print(\"Replacing : \",p)\n",
    "                textSnippet = textSnippet.replace(p,\"\")\n",
    "        \n",
    "        #print(\"Text : \",textSnippet)\n",
    "        #print(\"\\n\")\n",
    "        X.append(textSnippet)\n",
    "        Y.append(folder)\n",
    "    \n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "#print(X[:10])\n",
    "\n",
    "#from sklearn.feature_extraction import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tfidf = TfidfVectorizer(input='content',encoding='utf-8',decode_error='ignore',strip_accents='ascii',ngram_range=(2,2),stop_words='english',max_df=80,min_df=6,max_features=None,norm='l1')\n",
    "train = tfidf.fit_transform(X,Y)\n",
    "#print(tfidf.get_feature_names())\n",
    "#print(\"\\nWords Removed : \\n\",tfidf.stop_words_)\n",
    "#print(tfidf.build_analyzer())\n",
    "\n",
    "cv=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54166667  0.60869565  0.69565217  0.60869565  0.57142857]\n",
      "0.605227743271\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "acc = cross_val_score(clf_lr,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "print(acc)\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.375       0.39130435  0.39130435  0.39130435  0.38095238]\n",
      "0.385973084886\n",
      "[ 0.58333333  0.60869565  0.69565217  0.60869565  0.57142857]\n",
      "0.613561076605\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine Classifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "\n",
    "clf_svc = SVC(C=0.1,random_state=123)\n",
    "acc = cross_val_score(clf_svc,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "\n",
    "clf_svc = LinearSVC(C=0.1,random_state=123)\n",
    "acc = cross_val_score(clf_svc,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "print(acc)\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.58333333  0.60869565  0.69565217  0.60869565  0.61904762]\n",
      "0.623084886128\n"
     ]
    }
   ],
   "source": [
    "#Neural Network Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(5,10),activation=\"logistic\",solver=\"lbfgs\",alpha=0.01,learning_rate=\"adaptive\",max_iter=100,shuffle=True,early_stopping=True,random_state=123)\n",
    "acc = cross_val_score(clf_NN,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "print(acc)\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clustering Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0ee24708ced9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtestData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSnippetFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#for file in file_list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(folder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#files_list = [f for f in listdir(snippetFolder + \"/\" + folder)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'listdir' is not defined"
     ]
    }
   ],
   "source": [
    "testData = []\n",
    "file_list = [f for f in listdir(testSnippetFolder)]\n",
    "#for file in file_list:\n",
    "    #print(folder)\n",
    "    #files_list = [f for f in listdir(snippetFolder + \"/\" + folder)]\n",
    "    #print(files_list)\n",
    "    #print(\"\\n\")\n",
    "for file in file_list:\n",
    "    filePath = testSnippetFolder + \"/\" + file\n",
    "    #print(\"File Path : \", filePath)\n",
    "    f = open(filePath,'r',encoding='utf-8')\n",
    "    data = f.readlines()\n",
    "    #print(\"Data : \", data)\n",
    "    #for d in data:\n",
    "    #    d.replace(\"\\n\",\"\")\n",
    "    textSnippet = ''.join(data)\n",
    "    #print(\"Text : \",textSnippet)\n",
    "    textSnippet = textSnippet.replace(\"\\n\",\"\")\n",
    "    #textSnippet = textSnippet.replace('\"',\"\")\n",
    "\n",
    "    for p in puncs:\n",
    "        #print(p)\n",
    "        if p in textSnippet:\n",
    "            #print(\"Replacing : \",p)\n",
    "            textSnippet = textSnippet.replace(p,\"\")\n",
    "\n",
    "    #print(\"Text : \",textSnippet)\n",
    "    #print(\"\\n\")\n",
    "    testData.append(textSnippet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find out the top features used by each classifier"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
