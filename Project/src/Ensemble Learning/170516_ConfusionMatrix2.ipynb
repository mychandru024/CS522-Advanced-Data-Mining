{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#build confusion matrix\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#row in the confusion matrix\n",
    "pickle1 = \"/home/abc/ADM/pickle/Snippets.pkl\"\n",
    "\n",
    "#column in the confusion matrix\n",
    "pickle2 = \"/home/abc/ADM/pickle/Wikifier.pkl\"\n",
    "\n",
    "\n",
    "def createDictOfFromlistOfTuples(results):\n",
    "    d = { file_id : { \"l\" : label, \"p\" : prob } for file_id, label , prob in results}\n",
    "    return d\n",
    "\n",
    "def merge2dicts(d1, d2):\n",
    "    d1_keys = d1.keys()\n",
    "    d2_keys = d2.keys()\n",
    "        \n",
    "    merged_d = dict()\n",
    "    \n",
    "    for key in d1_keys:\n",
    "        if key in d2_keys:\n",
    "            merged_d.update({ key : { \"d1\" : d1[key], \"d2\" : d2[key] } })\n",
    "    return merged_d\n",
    "\n",
    "#d1 and d2 are two dicts having the results of classifiers\n",
    "def BuildConfusionMatrix(d1, d2, threshold):\n",
    "    \"\"\"\n",
    "    unique_labels = sorted(set(results1[i][1] for i in range(len(results1) - 1)))\n",
    "    d = dict()\n",
    "\n",
    "    for label in unique_labels:\n",
    "        d.update({label : Counter()})\n",
    "    d.update({\"No\" : Counter()})\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for i in range(len(results1)):\n",
    "        if results1[i][0] == results2[i][0]:\n",
    "            if results1[i][2] < threshold and  results2[i][2] > threshold:\n",
    "                d[\"No\"].update([results2[i][2]])\n",
    "            elif results1[i][2] > threshold and  results2[i][2] < threshold:\n",
    "                d[results1[i][2]].update([\"No\"])\n",
    "            elif results1[i][2] < threshold and  results2[i][2] < threshold:\n",
    "                d[\"No\"].update([\"No\"])\n",
    "            else:\n",
    "                d[results1[i]].update([results2[i]])\n",
    "    return pd.DataFrame(d, index=unique_labels, columns=unique_labels)\n",
    "    \"\"\"\n",
    "    m = defaultdict(lambda : 0)\n",
    "    d2_keys = d2.keys()\n",
    "    #print(d2_keys)\n",
    "    for key in d2_keys:\n",
    "        if isinstance(d2[key][\"l\"], str):\n",
    "            m.update( { d2[key][\"l\"] : Counter() } )\n",
    "            continue\n",
    "        labels_2 = d2[key][\"l\"]\n",
    "        for l in labels_2:\n",
    "            if l not in m.keys():\n",
    "                m.update( { l : Counter() } )\n",
    "    #m.update( { \"BT\" : Counter() } )\n",
    "    #print(m)\n",
    "    bt_count = 0 #below threshold count\n",
    "    for key in d2.keys():\n",
    "        if key in d1.keys():\n",
    "            if d2[key][\"p\"] > threshold and d1[key][\"p\"] > threshold:\n",
    "                #print(\"Adding\")\n",
    "                #m[d2[key][\"l\"]].update( [str(d1[key][\"l\"])] )\n",
    "                labels_2 = d2[key][\"l\"]\n",
    "                labels_1 = d1[key][\"l\"]\n",
    "                if isinstance(labels_2, str) and isinstance(labels_1, str):\n",
    "                    m[d2[key][\"l\"]].update( [str(d1[key][\"l\"])] )\n",
    "                else:\n",
    "                    #both are Wikifier results\n",
    "                    if not isinstance(labels_2, str) and not isinstance(labels_1, str):\n",
    "                        #print(\"if\")\n",
    "                        for k_2 in labels_2:\n",
    "                            for k_1 in labels_1:\n",
    "                                m[k_2].update( [k_1])\n",
    "                    #only first is wikifier results\n",
    "                    elif not isinstance(labels_1, str):\n",
    "                        #print(\"first elif\")\n",
    "                        for k_1 in d1[key][\"l\"]:\n",
    "                            m[d2[key][\"l\"]].update( [k_1])\n",
    "                    #only second is wikifier results\n",
    "                    elif not isinstance(labels_2, str):\n",
    "                        #print(\"second elif\")\n",
    "                        for k_2 in d2[key][\"l\"]:\n",
    "                            m[k_2].update( [d1[key][\"l\"]])\n",
    "            else:\n",
    "                bt_count += 1\n",
    "    print(bt_count)\n",
    "    #print(m)\n",
    "    return pd.DataFrame(m)\n",
    "          \n",
    "\n",
    "results1 = pickle.load(open(pickle1, 'rb'))\n",
    "results2 = pickle.load(open(pickle2, 'rb'))\n",
    "\n",
    "#print(results2)\n",
    "\n",
    "if \"Wikifier.pkl\" not in pickle1:\n",
    "    results_d1 = createDictOfFromlistOfTuples(results1)\n",
    "else:\n",
    "    results_d1 = results1\n",
    "    \n",
    "if \"Wikifier.pkl\" not in pickle2:\n",
    "    results_d2 = createDictOfFromlistOfTuples(results2)\n",
    "else:\n",
    "    results_d2 = results2\n",
    "\"\"\"\n",
    "results_d1 = { \"1\" : {\"l\" : \"arm\", \"p\" : 0.3}, \"2\" : {\"l\" : \"arch\", \"p\" : 0.4}, \"3\" : {\"l\" : \"soc\", \"p\" : 0.7}, \"4\" : {\"l\" : \"hist\", \"p\" : 1} }\n",
    "results_d2 = { \"1\" : {\"l\" : \"psy\", \"p\" : 0.4}, \"2\" : {\"l\" : \"art\", \"p\" : 0.5}, \"3\" : {\"l\" : \"chem\", \"p\" : 0.8}}\n",
    "\"\"\"\n",
    "\n",
    "cm_df = BuildConfusionMatrix(results_d1, results_d2, 0.2)\n",
    "#print(cm_df)\n",
    "writer = pd.ExcelWriter(\"Matrix.xlsx\")\n",
    "cm_df.to_excel(writer,\"sheet1\")\n",
    "writer.save()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: Counter({'abc': 1})}\n"
     ]
    }
   ],
   "source": [
    "d = dict()\n",
    "d.update({1 : Counter()})\n",
    "d[1].update([\"abc\"])\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       one  three  two\n",
      "one      5      0    1\n",
      "three    3      7    2\n",
      "two      2      1    4\n"
     ]
    }
   ],
   "source": [
    "d = {\"one\" : {\"one\" : 5, \"two\" : 2, \"three\" : 3},\\\n",
    "     \"two\" : {\"one\" : 1, \"two\" : 4, \"three\" : 2}, \\\n",
    "     \"three\" : {\"one\" : 0, \"two\" : 1, \"three\" : 7}}\n",
    "df = pd.DataFrame(d)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
