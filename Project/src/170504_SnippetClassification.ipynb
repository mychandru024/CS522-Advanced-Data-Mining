{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "164\n",
      "6\n",
      "110.0\n",
      "19\n",
      "['architecture chicago', 'architecture history', 'armour institute', 'art institute', 'art school', 'building chicago', 'carl condit', 'chicago school', 'chicago university', 'civics philanthropy', 'condit chicago', 'institute armour', 'institute technology', 'new york', 'school architecture', 'school chicago', 'school civics', 'university chicago', 'university illinois']\n",
      "(164, 19)\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import string\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Folder containing the labeled snippet subfolders for training the classifier\n",
    "#snippetFolder = \"/home/abc/ADM/Train_Data\" #for Chandra\n",
    "snippetFolder = \"Train_Data\" #for Dan\n",
    "\n",
    "#folder containing unlabeled snippets\n",
    "#testSnippetFolder = \"/home/abc/ADM/Test_Data\" #for Chandra\n",
    "testSnippetFolder = \"Test_Data\" #for Dan\n",
    "\n",
    "#folderToSaveResultsFile = \"/home/abc/ADM/Results\" #for Chandra\n",
    "folderToSaveResultsFile = \"Results\" #for Dan\n",
    "\n",
    "#list of all folders in the training data\n",
    "folder_list = [f for f in listdir(snippetFolder) if not f.startswith('.')]\n",
    "\n",
    "puncs = string.punctuation\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for folder in folder_list:\n",
    "    files_list = [f for f in listdir(snippetFolder + \"/\" + folder) if not f.startswith('.')]\n",
    "    for file in files_list:\n",
    "        filePath = snippetFolder + \"/\" + folder + \"/\" + file\n",
    "        f = open(filePath,'r',encoding='utf-8')\n",
    "        data = f.readlines()\n",
    "        textSnippet = ''.join(data)\n",
    "        textSnippet = textSnippet.replace(\"\\n\",\"\")\n",
    "        for p in puncs:\n",
    "            if p in textSnippet:\n",
    "                textSnippet = textSnippet.replace(p,\" \")\n",
    "        X.append(textSnippet)\n",
    "        Y.append(folder)\n",
    "    \n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "\n",
    "#maximum number of features you want to consider to build the model\n",
    "max_features = None #None means no limit\n",
    "\n",
    "#which n-gram model to use? if low is 2 and high is 5, we will consider all 2-grams to 5-grams\n",
    "low = 2 \n",
    "high = 2\n",
    "\n",
    "#word occurences\n",
    "min_freq = 6 #np.ceil(len(X) / 10)\n",
    "max_freq = np.ceil(len(X) / 1.5)\n",
    "\n",
    "print(min_freq)\n",
    "print(max_freq)\n",
    "\n",
    "#number of folds for cross-validation\n",
    "cv=5\n",
    "\n",
    "\n",
    "\n",
    "#from sklearn.feature_extraction import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\"\"\"\n",
    "tfidf = TfidfVectorizer(input='content',encoding='utf-8',decode_error='ignore',strip_accents='ascii',\\\n",
    "                        ngram_range=(2,2),stop_words='english',max_df=80,min_df=6,max_features=None,\\\n",
    "                        norm='l1')\n",
    "\"\"\"\n",
    "tfidf = TfidfVectorizer(input='content', encoding='utf-8', decode_error='ignore', strip_accents='ascii',\\\n",
    "                        ngram_range=(low,high), stop_words='english', max_features=max_features, norm='l1',\\\n",
    "                        max_df=max_freq, min_df=min_freq)\n",
    "train = tfidf.fit_transform(X,Y)\n",
    "print(len(tfidf.get_feature_names()))\n",
    "print(tfidf.get_feature_names())\n",
    "print(train.shape)\n",
    "#print(\"\\nWords Removed : \\n\",tfidf.stop_words_)\n",
    "#print(tfidf.build_analyzer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.531746031746\n",
      "                Features   weights\n",
      "16         school civics  0.431223\n",
      "14   school architecture  0.177500\n",
      "10        condit chicago  0.112025\n",
      "7         chicago school  0.109621\n",
      "17    university chicago  0.059994\n",
      "3          art institute  0.047796\n",
      "6            carl condit  0.021228\n",
      "0   architecture chicago  0.016355\n",
      "13              new york  0.013130\n",
      "2       armour institute  0.011128\n",
      "12  institute technology  0.000000\n",
      "15        school chicago  0.000000\n",
      "9    civics philanthropy  0.000000\n",
      "11      institute armour  0.000000\n",
      "1   architecture history  0.000000\n",
      "8     chicago university  0.000000\n",
      "5       building chicago  0.000000\n",
      "4             art school  0.000000\n",
      "18   university illinois  0.000000\n",
      "['CPS' 'CS_Armour' 'CS_Sullivan' 'CS_Tallmadge' 'CS_civics']\n",
      "19\n",
      "5\n",
      "19\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "criterion = [\"gini\",\"entropy\"]\n",
    "splitter = [\"best\", \"random\"]\n",
    "\n",
    "\n",
    "clf_dt = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_features=None, max_depth=None, \\\n",
    "                                min_samples_split=2, min_samples_leaf=1, max_leaf_nodes=None, \\\n",
    "                                class_weight=\"balanced\", random_state=123, presort=False)\n",
    "\n",
    "dt_acc = cross_val_score(clf_dt,train,Y,scoring=\"accuracy\",cv=3)\n",
    "#print(acc)\n",
    "print(np.mean(dt_acc))\n",
    "\n",
    "clf_dt.fit(train, Y)\n",
    "\n",
    "#print(len(clf_dt.feature_importances_))\n",
    "#print(clf_dt.feature_importances_)\n",
    "#print(clf_dt.tree_)\n",
    "#tree.export_graphviz(clf_dt,out_file='tree.dot')\n",
    "df = pd.DataFrame(data= {\"Features\" : tfidf.get_feature_names(), \"weights\" : clf_dt.feature_importances_})\n",
    "df = df.sort_values(axis=0,by='weights',ascending=False)\n",
    "print(df)\n",
    "\n",
    "\n",
    "print(clf_dt.classes_)\n",
    "\n",
    "\"\"\"\n",
    "import io\n",
    "import pydot\n",
    "\n",
    "def show_tree(decisionTree, file_path):\n",
    "    dotfile = io.StringIO()\n",
    "    tree.export_graphviz(decisionTree, out_file=dotfile)\n",
    "    pydot.graph_from_dot_data(dotfile.getvalue()).write_png(file_path)\n",
    "    i = misc.imread(file_path)\n",
    "    plt.imshow(i)\n",
    "\n",
    "# To use it\n",
    "show_tree(clf_dt, 'test.png')\n",
    "\"\"\"\n",
    "print(clf_dt.max_features_)\n",
    "print(clf_dt.n_classes_)\n",
    "print(clf_dt.n_features_)\n",
    "print(clf_dt.n_outputs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.511051511281\n",
      "                Features   weights\n",
      "9    civics philanthropy  0.244480\n",
      "16         school civics  0.169699\n",
      "14   school architecture  0.147133\n",
      "7         chicago school  0.137187\n",
      "10        condit chicago  0.095494\n",
      "17    university chicago  0.056201\n",
      "3          art institute  0.049136\n",
      "6            carl condit  0.040422\n",
      "13              new york  0.019718\n",
      "8     chicago university  0.015743\n",
      "0   architecture chicago  0.008937\n",
      "5       building chicago  0.005657\n",
      "12  institute technology  0.005296\n",
      "18   university illinois  0.002800\n",
      "15        school chicago  0.002097\n",
      "11      institute armour  0.000000\n",
      "1   architecture history  0.000000\n",
      "4             art school  0.000000\n",
      "2       armour institute  0.000000\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier - Ensemble Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=10,criterion=\"gini\", max_features=None, max_depth=None, \\\n",
    "                                min_samples_split=2, min_samples_leaf=1, max_leaf_nodes=None, \\\n",
    "                                class_weight=\"balanced\", random_state=123)\n",
    "\n",
    "rf_acc = cross_val_score(clf_rf,train,Y,scoring=\"accuracy\",cv=6)\n",
    "#print(acc)\n",
    "print(np.mean(rf_acc))\n",
    "\n",
    "clf_rf.fit(train, Y)\n",
    "\n",
    "#print(len(clf_dt.feature_importances_))\n",
    "#print(clf_dt.feature_importances_)\n",
    "#print(clf_dt.tree_)\n",
    "#tree.export_graphviz(clf_dt,out_file='tree.dot')\n",
    "df = pd.DataFrame(data= {\"Features\" : tfidf.get_feature_names(), \"weights\" : clf_rf.feature_importances_})\n",
    "df = df.sort_values(axis=0,by='weights',ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C :  100 , class_weight :  balanced , max_iter :  100\n",
      "0.646268503002\n",
      "['CPS' 'CS_Armour' 'CS_Sullivan' 'CS_Tallmadge' 'CS_civics']\n",
      "5\n",
      "\n",
      "Feature weights for class :  CPS \n",
      "\n",
      "                Features   weights\n",
      "17    university chicago  6.534951\n",
      "7         chicago school -1.226555\n",
      "11      institute armour -2.956993\n",
      "4             art school -3.354082\n",
      "18   university illinois -4.130375\n",
      "1   architecture history -4.227729\n",
      "12  institute technology -4.404609\n",
      "15        school chicago -4.626861\n",
      "5       building chicago -4.765111\n",
      "2       armour institute -4.907169\n",
      "9    civics philanthropy -5.014145\n",
      "16         school civics -5.096588\n",
      "6            carl condit -5.562290\n",
      "13              new york -5.601089\n",
      "3          art institute -5.701100\n",
      "10        condit chicago -5.936499\n",
      "0   architecture chicago -6.455351\n",
      "8     chicago university -8.618173\n",
      "14   school architecture -9.948146\n",
      "\n",
      "Feature weights for class :  CS_Armour \n",
      "\n",
      "                Features    weights\n",
      "3          art institute  11.095114\n",
      "18   university illinois   7.093059\n",
      "2       armour institute   6.383234\n",
      "12  institute technology   6.194400\n",
      "4             art school   5.295497\n",
      "8     chicago university   3.301008\n",
      "0   architecture chicago   2.684082\n",
      "14   school architecture   2.543220\n",
      "11      institute armour   2.485209\n",
      "13              new york   0.575726\n",
      "15        school chicago   0.068856\n",
      "7         chicago school  -1.556434\n",
      "1   architecture history  -2.187563\n",
      "5       building chicago  -2.618499\n",
      "9    civics philanthropy  -3.007027\n",
      "16         school civics  -3.009972\n",
      "6            carl condit  -5.103103\n",
      "10        condit chicago  -5.698859\n",
      "17    university chicago  -7.902048\n",
      "\n",
      "Feature weights for class :  CS_Sullivan \n",
      "\n",
      "                Features   weights\n",
      "6            carl condit  9.995445\n",
      "10        condit chicago  9.796914\n",
      "1   architecture history  6.454768\n",
      "17    university chicago  2.423329\n",
      "8     chicago university  2.423329\n",
      "13              new york  0.601216\n",
      "14   school architecture  0.538464\n",
      "7         chicago school  0.275601\n",
      "5       building chicago -0.737296\n",
      "11      institute armour -1.732029\n",
      "0   architecture chicago -2.199568\n",
      "4             art school -2.959169\n",
      "15        school chicago -3.019981\n",
      "9    civics philanthropy -3.077033\n",
      "16         school civics -3.117276\n",
      "12  institute technology -3.216286\n",
      "2       armour institute -3.809728\n",
      "18   university illinois -4.335073\n",
      "3          art institute -5.836684\n",
      "\n",
      "Feature weights for class :  CS_Tallmadge \n",
      "\n",
      "                Features   weights\n",
      "5       building chicago  6.877383\n",
      "15        school chicago  6.507520\n",
      "7         chicago school  4.482315\n",
      "13              new york  4.155453\n",
      "0   architecture chicago  3.710427\n",
      "14   school architecture  2.816051\n",
      "11      institute armour -0.338098\n",
      "4             art school -1.142513\n",
      "9    civics philanthropy -1.211737\n",
      "1   architecture history -1.240523\n",
      "16         school civics -1.250484\n",
      "2       armour institute -1.720622\n",
      "8     chicago university -1.921378\n",
      "17    university chicago -1.921378\n",
      "12  institute technology -2.194532\n",
      "18   university illinois -2.252233\n",
      "10        condit chicago -3.380361\n",
      "6            carl condit -4.323725\n",
      "3          art institute -6.255897\n",
      "\n",
      "Feature weights for class :  CS_civics \n",
      "\n",
      "                Features    weights\n",
      "16         school civics  11.177902\n",
      "9    civics philanthropy  10.452292\n",
      "11      institute armour  -0.524489\n",
      "1   architecture history  -0.531272\n",
      "4             art school  -0.559283\n",
      "17    university chicago  -0.682128\n",
      "8     chicago university  -0.682128\n",
      "15        school chicago  -0.785529\n",
      "5       building chicago  -0.791088\n",
      "18   university illinois  -0.795933\n",
      "12  institute technology  -0.974482\n",
      "2       armour institute  -1.053202\n",
      "6            carl condit  -1.118321\n",
      "13              new york  -1.138300\n",
      "10        condit chicago  -1.200713\n",
      "0   architecture chicago  -1.325404\n",
      "3          art institute  -1.396101\n",
      "7         chicago school  -3.041055\n",
      "14   school architecture  -3.245137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ny = np.array(Y)\\nfrom sklearn.model_selection import KFold\\nkfold = KFold(n_splits=5, shuffle=True, random_state=1234)\\npreds = []\\ntruths = []\\nfor tr, tst in kfold.split(train):\\n    #print(\\'%d training instances and %d testing instances\\' %(len(tr), len(test)))\\n    clf_lr_2 = LogisticRegression(class_weight=\"balanced\",C=100,max_iter=100,random_state=123)\\n    clf_lr_2.fit(train[tr], y[tr])\\n    Y_pred = clf_lr_2.predict(train[tst])\\n    preds.extend(Y_pred)\\n    truths.extend(y[tst])\\n    acc = accuracy_score(y[tst], Y_pred)\\n    print(acc)\\nc_m = confusion_matrix(truths, preds,labels=clf_lr_2.classes_)\\ncm_df = pd.DataFrame(c_m,index=clf_lr.classes_,columns=clf_lr_2.classes_)\\nprint(cm_df)\\n#print(confusion_matrix(y[tst], Y_pred, clf_lr.classes_))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Cs = [0.001,0.01,0.1,1,10,100,1000]\n",
    "Cs = [100]\n",
    "\n",
    "#CW = [\"balanced\",None]\n",
    "CW = [\"balanced\"]\n",
    "\n",
    "#ITR = [50,100,200,300,400]\n",
    "ITR = [100]\n",
    "\n",
    "for c in Cs:\n",
    "    for cw in CW:\n",
    "        for itr in ITR:\n",
    "            print(\"C : \",c,\", class_weight : \",cw,\", max_iter : \",itr)\n",
    "            clf_lr = LogisticRegression(class_weight=cw,C=c,max_iter=itr,random_state=123)\n",
    "            acc = cross_val_score(clf_lr,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "            #print(acc)\n",
    "            print(np.mean(acc))\n",
    "\n",
    "clf_lr.fit(train,Y)\n",
    "\n",
    "print(clf_lr.classes_)\n",
    "\n",
    "print(len(clf_lr.coef_))\n",
    "\n",
    "#print(clf_lr.coef_)\n",
    "for i, cls in enumerate(clf_lr.classes_):\n",
    "    print(\"\\nFeature weights for class : \",cls,\"\\n\")\n",
    "    df = pd.DataFrame(data= {\"Features\" : tfidf.get_feature_names(), \"weights\" : clf_lr.coef_[i]})\n",
    "    df = df.sort_values(axis=0,by='weights',ascending=False)\n",
    "    print(df)\n",
    "\"\"\"\n",
    "y = np.array(Y)\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "preds = []\n",
    "truths = []\n",
    "for tr, tst in kfold.split(train):\n",
    "    #print('%d training instances and %d testing instances' %(len(tr), len(test)))\n",
    "    clf_lr_2 = LogisticRegression(class_weight=\"balanced\",C=100,max_iter=100,random_state=123)\n",
    "    clf_lr_2.fit(train[tr], y[tr])\n",
    "    Y_pred = clf_lr_2.predict(train[tst])\n",
    "    preds.extend(Y_pred)\n",
    "    truths.extend(y[tst])\n",
    "    acc = accuracy_score(y[tst], Y_pred)\n",
    "    print(acc)\n",
    "c_m = confusion_matrix(truths, preds,labels=clf_lr_2.classes_)\n",
    "cm_df = pd.DataFrame(c_m,index=clf_lr.classes_,columns=clf_lr_2.classes_)\n",
    "print(cm_df)\n",
    "#print(confusion_matrix(y[tst], Y_pred, clf_lr.classes_))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54285714  0.36363636  0.54545455  0.5625      0.58064516]\n",
      "0.519018642648\n",
      "C :  100 , class_weight :  balanced , max_iter :  100\n",
      "0.571598415026\n",
      "\n",
      "Feature weights for class :  CPS \n",
      "\n",
      "                Features   weights\n",
      "17    university chicago  2.079219\n",
      "11      institute armour -0.659891\n",
      "7         chicago school -0.880844\n",
      "13              new york -1.166040\n",
      "4             art school -1.172603\n",
      "18   university illinois -1.174168\n",
      "2       armour institute -1.175396\n",
      "12  institute technology -1.201965\n",
      "15        school chicago -1.232092\n",
      "5       building chicago -1.242903\n",
      "9    civics philanthropy -1.335171\n",
      "16         school civics -1.426332\n",
      "3          art institute -1.469628\n",
      "1   architecture history -1.516180\n",
      "10        condit chicago -1.529153\n",
      "6            carl condit -1.560202\n",
      "0   architecture chicago -1.838295\n",
      "14   school architecture -2.209645\n",
      "8     chicago university -4.367333\n",
      "\n",
      "Feature weights for class :  CS_Armour \n",
      "\n",
      "                Features       weights\n",
      "3          art institute  5.134192e+00\n",
      "12  institute technology  2.962260e+00\n",
      "2       armour institute  2.540877e+00\n",
      "18   university illinois  2.354363e+00\n",
      "8     chicago university  2.211822e+00\n",
      "4             art school  2.203869e+00\n",
      "0   architecture chicago  1.166933e+00\n",
      "14   school architecture  7.238330e-01\n",
      "13              new york  3.326442e-01\n",
      "1   architecture history -1.658253e-16\n",
      "11      institute armour -3.336861e-16\n",
      "5       building chicago -2.833383e-01\n",
      "7         chicago school -3.435931e-01\n",
      "16         school civics -4.050726e-01\n",
      "9    civics philanthropy -5.020655e-01\n",
      "15        school chicago -8.845210e-01\n",
      "6            carl condit -1.012027e+00\n",
      "10        condit chicago -1.676763e+00\n",
      "17    university chicago -5.505861e+00\n",
      "\n",
      "Feature weights for class :  CS_Sullivan \n",
      "\n",
      "                Features   weights\n",
      "10        condit chicago  4.288160\n",
      "6            carl condit  4.229243\n",
      "1   architecture history  3.853220\n",
      "17    university chicago  1.053465\n",
      "7         chicago school  0.696132\n",
      "8     chicago university  0.561629\n",
      "13              new york  0.236752\n",
      "14   school architecture -0.036167\n",
      "5       building chicago -0.347332\n",
      "0   architecture chicago -0.377220\n",
      "16         school civics -0.490423\n",
      "9    civics philanthropy -0.490423\n",
      "11      institute armour -0.585774\n",
      "15        school chicago -0.650027\n",
      "4             art school -0.710009\n",
      "18   university illinois -0.794559\n",
      "2       armour institute -1.094797\n",
      "12  institute technology -1.169192\n",
      "3          art institute -1.727820\n",
      "\n",
      "Feature weights for class :  CS_Tallmadge \n",
      "\n",
      "                Features       weights\n",
      "5       building chicago  2.817713e+00\n",
      "15        school chicago  2.281516e+00\n",
      "7         chicago school  1.389532e+00\n",
      "0   architecture chicago  4.827203e-01\n",
      "14   school architecture  4.754426e-01\n",
      "13              new york  4.752446e-01\n",
      "18   university illinois  2.162949e-16\n",
      "4             art school  2.553296e-17\n",
      "11      institute armour -3.974490e-17\n",
      "1   architecture history -2.996532e-16\n",
      "8     chicago university -2.333496e-01\n",
      "17    university chicago -2.333496e-01\n",
      "9    civics philanthropy -3.094965e-01\n",
      "16         school civics -6.189931e-01\n",
      "2       armour institute -8.779970e-01\n",
      "12  institute technology -8.978437e-01\n",
      "10        condit chicago -1.007415e+00\n",
      "6            carl condit -2.468141e+00\n",
      "3          art institute -2.980690e+00\n",
      "\n",
      "Feature weights for class :  CS_civics \n",
      "\n",
      "                Features   weights\n",
      "16         school civics  2.486217\n",
      "9    civics philanthropy  1.996993\n",
      "18   university illinois -0.004693\n",
      "11      institute armour -0.004780\n",
      "5       building chicago -0.004873\n",
      "10        condit chicago -0.005046\n",
      "1   architecture history -0.005138\n",
      "4             art school -0.005199\n",
      "3          art institute -0.005217\n",
      "0   architecture chicago -0.005229\n",
      "8     chicago university -0.005278\n",
      "17    university chicago -0.005278\n",
      "7         chicago school -0.005297\n",
      "2       armour institute -0.005407\n",
      "13              new york -0.005419\n",
      "12  institute technology -0.005507\n",
      "15        school chicago -0.005652\n",
      "6            carl condit -0.005867\n",
      "14   school architecture -0.006891\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine Classifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "\n",
    "clf_svc = SVC(C=10,random_state=123,class_weight=\"balanced\")\n",
    "acc = cross_val_score(clf_svc,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "\n",
    "clf_svc.fit(train,Y)\n",
    "\n",
    "for c in Cs:\n",
    "    for cw in CW:\n",
    "        for itr in ITR:\n",
    "            print(\"C : \",c,\", class_weight : \",cw,\", max_iter : \",itr)\n",
    "            clf_linear_svc = LinearSVC(C=c,random_state=123,class_weight=cw,max_iter=itr)\n",
    "            acc = cross_val_score(clf_linear_svc,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "            #print(acc)\n",
    "            print(np.mean(acc))\n",
    "\n",
    "clf_linear_svc.fit(train,Y)\n",
    "\n",
    "for i, cls in enumerate(clf_linear_svc.classes_):\n",
    "    print(\"\\nFeature weights for class : \",cls,\"\\n\")\n",
    "    df = pd.DataFrame(data= {\"Features\" : tfidf.get_feature_names(), \"weights\" : clf_linear_svc.coef_[i]})\n",
    "    df = df.sort_values(axis=0,by='weights',ascending=False)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.628433005167\n",
      "3\n",
      "['CPS' 'CS_Armour' 'CS_Sullivan' 'CS_Tallmadge' 'CS_civics']\n",
      "\n",
      "Feature :  architecture chicago\n",
      "[-1.29796836  1.51467781 -1.19903216  0.14965242  0.42861058]\n",
      "\n",
      "Feature :  architecture history\n",
      "[ 0.63810571 -0.39548631 -1.18199277  0.48327389  0.44729108]\n",
      "\n",
      "Feature :  armour institute\n",
      "[-1.33798021  0.93776699  0.11990895  0.60719221 -0.56078082]\n",
      "\n",
      "Feature :  art institute\n",
      "[-2.0542376   1.13760072  0.44246113  1.23982586 -1.21849858]\n",
      "\n",
      "Feature :  art school\n",
      "[-1.09063163  0.72822279  0.14753915  0.48426503 -0.47093018]\n",
      "\n",
      "Feature :  building chicago\n",
      "[-0.21778443  1.10154319 -1.07826517 -0.63447455  1.14366181]\n",
      "\n",
      "Feature :  carl condit\n",
      "[ 1.45798126 -1.34504964 -1.88755399  1.08289292  0.59574408]\n",
      "\n",
      "Feature :  chicago school\n",
      "[ 1.03279949  0.5005507  -0.13855228 -2.1172376   2.12872141]\n",
      "\n",
      "Feature :  chicago university\n",
      "[-0.81430997  0.57287546 -2.39558001  1.5289156   0.16402087]\n",
      "\n",
      "Feature :  civics philanthropy\n",
      "[-0.039446   -1.3138943   0.80130807  1.91005309 -1.74163358]\n",
      "\n",
      "Feature :  condit chicago\n",
      "[ 1.53894236 -1.29450456 -1.86148808  0.95952048  0.69625152]\n",
      "\n",
      "Feature :  institute armour\n",
      "[-0.5799916   0.50383016 -0.01951315  0.1764276  -0.1342073 ]\n",
      "\n",
      "Feature :  institute technology\n",
      "[-1.13271148  0.77084909  0.10628049  0.59210847 -0.51816385]\n",
      "\n",
      "Feature :  new york\n",
      "[-0.58790085  0.67863297 -1.49975413 -0.02126679  0.40477441]\n",
      "\n",
      "Feature :  school architecture\n",
      "[-0.88320688  1.5023638  -2.14965478  2.00043491 -0.16738995]\n",
      "\n",
      "Feature :  school chicago\n",
      "[-0.6191018   1.45409569 -0.63429553 -0.55580883  0.7274267 ]\n",
      "\n",
      "Feature :  school civics\n",
      "[-0.08394796 -1.34871979  0.82337274  2.02274105 -1.83986003]\n",
      "\n",
      "Feature :  university chicago\n",
      "[ 2.68490162 -2.40134348  1.06488659 -0.74174931 -0.05229033]\n",
      "\n",
      "Feature :  university illinois\n",
      "[-1.39594255  0.87171992  0.26755508  0.65377025 -0.67415195]\n"
     ]
    }
   ],
   "source": [
    "#Neural Network Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\"\"\"\n",
    "act = [\"logistic\",\"tanh\",\"relu\"]\n",
    "hl = [(5,5),(5,10),(10,10),(10,15),(15,15),(15,20),(20,20)]\n",
    "lr = [\"constant\",\"adaptive\"]\n",
    "erly_stop = [True,False]\n",
    "shuffle = [True,False]\n",
    "solver = [\"lbfgs\",\"sgd\"]\n",
    "alpha = [0.01,0.1,1,10,100]\n",
    "\n",
    "for a in act:\n",
    "    for h in hl:\n",
    "        for l in lr:\n",
    "            for e_s in erly_stop:\n",
    "                for s in shuffle:\n",
    "                    for m in ITR:\n",
    "                        for so in solver:\n",
    "                            for al in alpha:\n",
    "                                print(\"Activation : \",a,\" hidden layers : \",h,\" learning rate : \",l,\" early_stopping : \",e_s,\" Shuffle : \",s,\" max_iter : \",m,\" solver :\",so,\" Alpha : \",a)\n",
    "                                clf_NN = MLPClassifier(hidden_layer_sizes=h,activation=a,solver=so,alpha=al,learning_rate=l,max_iter=m,shuffle=s,early_stopping=e_s,random_state=123)\n",
    "                                acc = cross_val_score(clf_NN,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "                                #print(acc)\n",
    "                                print(np.mean(acc))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "clf_NN = MLPClassifier(hidden_layer_sizes=(5,5), activation=\"logistic\", solver=\"lbfgs\", alpha=0.1, \\\n",
    "                       learning_rate=\"constant\", max_iter=300, shuffle=False, early_stopping=True, \\\n",
    "                       random_state=123)\n",
    "NN_acc = cross_val_score(clf_NN,train,Y,scoring=\"accuracy\",cv=cv)\n",
    "#print(acc)\n",
    "print(np.mean(NN_acc))\n",
    "\n",
    "clf_NN.fit(train,Y)\n",
    "print(len(clf_NN.coefs_))\n",
    "#print(clf_NN.coefs_)\n",
    "print(clf_NN.classes_)\n",
    "\n",
    "\"\"\"\n",
    "for i, cls in enumerate(clf_NN.classes_):\n",
    "    print(\"\\nFeature weights for class : \",cls,\"\\n\")\n",
    "    df = pd.DataFrame(data= {\"Features\" : tfidf.get_feature_names(), \"weights\" : clf_NN.coefs_[i]})\n",
    "    df = df.sort_values(axis=0,by='weights',ascending=False)\n",
    "    print(df)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "for i, layer_weights in enumerate(clf_NN.coefs_):\n",
    "    print(\"\\nLayer : \",i)\n",
    "    for j, feature in enumerate(tfidf.get_feature_names()):\n",
    "        print(\"\\nFeature : \",feature)\n",
    "        print(\"\\nCorresponding weights in layer(Note : The ith element in the list represents the weight matrix corresponding to layer i.) : \")\n",
    "        print(layer_weights[j])\n",
    "\"\"\"\n",
    "\n",
    "for j, feature in enumerate(tfidf.get_feature_names()):\n",
    "    print(\"\\nFeature : \",feature)  \n",
    "    print(clf_NN.coefs_[0][j])\n",
    "    \"\"\"\n",
    "    for i, layer_weights in enumerate(clf_NN.coefs_[0]):\n",
    "        print(\"Layer : \",i)\n",
    "        #print(\"\\nCorresponding weights in layer(Note : The ith element in the list represents the weight matrix corresponding to layer i.) : \")\n",
    "        print(layer_weights[j])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData = []\n",
    "#list of all snippet files in the test data\n",
    "file_list = [f for f in listdir(testSnippetFolder) if not f.startswith('.')]\n",
    "\n",
    "for file in file_list:\n",
    "    filePath = testSnippetFolder + \"/\" + file\n",
    "    f = open(filePath,'r',encoding='utf-8')\n",
    "    data = f.readlines()\n",
    "    textSnippet = ''.join(data)\n",
    "    textSnippet = textSnippet.replace(\"\\n\",\"\")\n",
    "    for p in puncs:\n",
    "        if p in textSnippet:\n",
    "            textSnippet = textSnippet.replace(p,\"\")\n",
    "    testData.append(textSnippet)\n",
    "    \n",
    "#use same vectorizer used to train data\n",
    "test = tfidf.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPS' 'CS_Armour' 'CS_Sullivan' 'CS_Tallmadge' 'CS_civics']\n",
      "[[  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  6.11416536e-03   3.51802651e-01   2.85995746e-01   3.53921355e-01\n",
      "    2.16608202e-03]\n",
      " [  2.44855214e-02   1.22209126e-02   1.46813113e-02   7.17514091e-03\n",
      "    9.41437114e-01]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.88285089e-01   1.99822294e-02   5.84697437e-01   2.42960929e-03\n",
      "    4.60563533e-03]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  2.23644611e-02   2.27707570e-01   2.91285165e-01   4.55286518e-01\n",
      "    3.35628633e-03]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  5.27509374e-03   4.47930576e-02   9.13255660e-01   3.42938043e-02\n",
      "    2.38238474e-03]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  1.93759794e-02   9.76050343e-01   2.33319533e-03   2.29087670e-04\n",
      "    2.01139423e-03]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  4.46137044e-03   9.83661572e-01   9.12423187e-03   1.38763281e-03\n",
      "    1.36519266e-03]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  6.63989214e-01   1.63739063e-01   1.51560641e-01   8.34720397e-03\n",
      "    1.23638787e-02]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  2.23644611e-02   2.27707570e-01   2.91285165e-01   4.55286518e-01\n",
      "    3.35628633e-03]\n",
      " [  6.92880895e-03   9.25058915e-01   2.87647190e-02   3.67983343e-02\n",
      "    2.44922256e-03]\n",
      " [  1.82297698e-02   1.08159389e-02   1.11557767e-02   4.42714455e-03\n",
      "    9.55371370e-01]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  6.63989214e-01   1.63739063e-01   1.51560641e-01   8.34720397e-03\n",
      "    1.23638787e-02]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]]\n",
      "[('3102088__1.txt', 'CS_Armour', 0.43587076982093659), ('hvd.32044039365119__10.txt', 'CS_Armour', 0.43587076982093659), ('468039__33.txt', 'CS_Tallmadge', 0.41619178001575868), ('nnc1.cu04264290__1.txt', 'CS_Armour', 0.43587076982093659), ('1425278__2.txt', 'CS_Tallmadge', 0.41619178001575868), ('mdp.39015031294864__1.txt', 'CS_Tallmadge', 0.41619178001575868), ('774830__1.txt', 'CS_Tallmadge', 0.35392135529557855), ('hvd.32044039365119__2.txt', 'CS_civics', 0.94143711374350703), ('njp.32101059234532__1.txt', 'CS_Armour', 0.43587076982093659), ('1997_1047944__2.txt', 'CS_Sullivan', 0.58469743678698904), ('25505243__2.txt', 'CS_Armour', 0.43587076982093659), ('nnc1.ar53666712__1.txt', 'CS_Tallmadge', 0.45528651787859303), ('nyp.33433071108827__4.txt', 'CS_Tallmadge', 0.41619178001575868), ('1991_990613__2.txt', 'CS_Sullivan', 0.91325565969605138), ('1959_1424016__1.txt', 'CS_Tallmadge', 0.41619178001575868), ('773093__1.txt', 'CS_Armour', 0.43587076982093659), ('mdp.39015082311138__1.txt', 'CS_Tallmadge', 0.41619178001575868), ('hvd.32044039365119__9.txt', 'CS_Armour', 0.97605034335213459), ('1424869__6.txt', 'CS_Tallmadge', 0.41619178001575868), ('mdp.39015059791270__1.txt', 'CS_Tallmadge', 0.41619178001575868), ('4117456__1.txt', 'CS_Armour', 0.43587076982093659), ('ncs1.ark+=13960=t45q5jt4w__1.txt', 'CS_Tallmadge', 0.41619178001575868), ('nyp.33433060463365__1.txt', 'CS_Tallmadge', 0.41619178001575868), ('4102638__1.txt', 'CS_Armour', 0.98366157222422912), ('mdp.39015046781350__1.txt', 'CS_Armour', 0.43587076982093659), ('mdp.39015081896352__1.txt', 'CPS', 0.66398921362362828), ('njp.32101076188927__1.txt', 'CS_Armour', 0.43587076982093659), ('mdp.39015062797538__1.txt', 'CS_Tallmadge', 0.45528651787859303), ('njp.32101082377712__5.txt', 'CS_Armour', 0.92505891514294525), ('hvd.32044039365119__3.txt', 'CS_civics', 0.95537137011672724), ('njp.32101082377183__2.txt', 'CS_Tallmadge', 0.41619178001575868), ('njp.32101082377423__1.txt', 'CS_Tallmadge', 0.41619178001575868), ('1076072__1.txt', 'CPS', 0.66398921362362828), ('mdp.39015062810638__1.txt', 'CS_Armour', 0.43587076982093659), ('hvd.fl4rb6__1.txt', 'CS_Tallmadge', 0.41619178001575868)]\n",
      "['CPS' 'CS_Armour' 'CS_Sullivan' 'CS_Tallmadge' 'CS_civics']\n",
      "['CS_Armour' 'CS_Armour' 'CS_Tallmadge' 'CS_Armour' 'CS_Tallmadge'\n",
      " 'CS_Tallmadge' 'CS_Tallmadge' 'CS_civics' 'CS_Armour' 'CS_Sullivan'\n",
      " 'CS_Armour' 'CS_Tallmadge' 'CS_Tallmadge' 'CS_Sullivan' 'CS_Tallmadge'\n",
      " 'CS_Armour' 'CS_Tallmadge' 'CS_Armour' 'CS_Tallmadge' 'CS_Tallmadge'\n",
      " 'CS_Armour' 'CS_Tallmadge' 'CS_Tallmadge' 'CS_Armour' 'CS_Armour' 'CPS'\n",
      " 'CS_Armour' 'CS_Tallmadge' 'CS_Armour' 'CS_civics' 'CS_Tallmadge'\n",
      " 'CS_Tallmadge' 'CPS' 'CS_Armour' 'CS_Tallmadge']\n",
      "[[  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  6.11416536e-03   3.51802651e-01   2.85995746e-01   3.53921355e-01\n",
      "    2.16608202e-03]\n",
      " [  2.44855214e-02   1.22209126e-02   1.46813113e-02   7.17514091e-03\n",
      "    9.41437114e-01]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.88285089e-01   1.99822294e-02   5.84697437e-01   2.42960929e-03\n",
      "    4.60563533e-03]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  2.23644611e-02   2.27707570e-01   2.91285165e-01   4.55286518e-01\n",
      "    3.35628633e-03]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  5.27509374e-03   4.47930576e-02   9.13255660e-01   3.42938043e-02\n",
      "    2.38238474e-03]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  1.93759794e-02   9.76050343e-01   2.33319533e-03   2.29087670e-04\n",
      "    2.01139423e-03]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  4.46137044e-03   9.83661572e-01   9.12423187e-03   1.38763281e-03\n",
      "    1.36519266e-03]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  6.63989214e-01   1.63739063e-01   1.51560641e-01   8.34720397e-03\n",
      "    1.23638787e-02]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  2.23644611e-02   2.27707570e-01   2.91285165e-01   4.55286518e-01\n",
      "    3.35628633e-03]\n",
      " [  6.92880895e-03   9.25058915e-01   2.87647190e-02   3.67983343e-02\n",
      "    2.44922256e-03]\n",
      " [  1.82297698e-02   1.08159389e-02   1.11557767e-02   4.42714455e-03\n",
      "    9.55371370e-01]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]\n",
      " [  6.63989214e-01   1.63739063e-01   1.51560641e-01   8.34720397e-03\n",
      "    1.23638787e-02]\n",
      " [  3.73167515e-03   4.35870770e-01   2.82450320e-01   2.77258020e-01\n",
      "    6.89214677e-04]\n",
      " [  3.58619548e-01   3.87094945e-02   1.85895710e-01   4.16191780e-01\n",
      "    5.83467808e-04]]\n"
     ]
    }
   ],
   "source": [
    "#which classifier to use for classification of the test data?\n",
    "Y_test_lr = clf_lr.predict(test)\n",
    "probs = clf_lr.predict_proba(test)\n",
    "print(clf_lr.classes_)\n",
    "print(probs)\n",
    "\n",
    "Y_probs = []\n",
    "\n",
    "classes = list(clf_lr.classes_)\n",
    "\n",
    "for i,label in enumerate(Y_test_lr):\n",
    "    label_index = classes.index(label)\n",
    "    max_prob = probs[i][label_index]\n",
    "    Y_probs.append(max_prob)\n",
    "    \n",
    "label_prob = []\n",
    "l = len(Y_test_lr)\n",
    "for i in range(l):\n",
    "    label_prob.append((file_list[i],Y_test_lr[i],Y_probs[i]))\n",
    "print(label_prob)\n",
    "import pickle\n",
    "\n",
    "pickle.dump(label_prob, open(folderToSaveResultsFile + \"/\" + 'Snippets.pkl', 'wb'))\n",
    "\n",
    "\"\"\"\n",
    "Y_test_svc = clf_svc.predict(test)\n",
    "\n",
    "Y_test_linear_svc = clf_linear_svc.predict(test)\n",
    "\n",
    "Y_test_nn = clf_NN.predict(test)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "print(len(file_list))\n",
    "print(len(Y_test_lr))\n",
    "\n",
    "#final list containing of (snippet file name, predicted class label) \n",
    "final_list = []\n",
    "l = len(file_list)\n",
    "for i in range(l):\n",
    "    final_list.append((file_list[i],Y_test_lr[i]))\n",
    "print(final_list)\n",
    "\n",
    "#dict of string(key) : list (value)\n",
    "#class label as key, and list of snippets classified into this label as values\n",
    "d = dict()\n",
    "for t in final_list:\n",
    "    if t[1] not in d.keys():\n",
    "        d[t[1]] = [t[0]]\n",
    "    else:\n",
    "        d[t[1]].append(t[0])\n",
    "\n",
    "for key, values in d.items():\n",
    "    with open(folderToSaveResultsFile + \"/\" + key + \".txt\",\"a\") as out_file:\n",
    "        for item in values :\n",
    "            out_file.write(item+\"\\n\")\n",
    "\n",
    "#print(d)\n",
    "print(\"Done\")\n",
    "\"\"\"\n",
    "print(clf_lr.classes_)\n",
    "print(Y_test_lr)\n",
    "print(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try clustering techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try word2vec model\n",
    "from nltk.corpus import brown\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(brown.sents(),size=50,window=5,min_count=1,workers=2)\n",
    "w2v_model_wv = w2v_model.wv\n",
    "del w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_feature_dicts(data, w2v_model_wv, w2v=True, token=True, caps=True, context=True):\n",
    "    list_of_dicts = []\n",
    "    #labels = []\n",
    "\n",
    "    for sentence_data in data:\n",
    "        #print(sentence_data)\n",
    "        sentence_dict = dict()   \n",
    "        words = sentence_data.split(\" \")\n",
    "        sentence_length = len(words)\n",
    "        #print(sentence_length)\n",
    "        current_token = \"\"\n",
    "        current_is_caps = 0\n",
    "        current_wv = []\n",
    "        prev_wv = []\n",
    "        next_wv = []\n",
    "        prev_token = \"\"\n",
    "        prev_is_caps = 0      \n",
    "        next_token = \"\"\n",
    "        next_is_caps = 0\n",
    "        \n",
    "        for i in range(sentence_length-1):\n",
    "            #print(i,\"th\", \" Word : \",words[i],\"Length : \",len(words[i]))\n",
    "            #print(i+1,\"th\", \" Word : \",words[i+1],\"Length : \",len(words[i+1]))\n",
    "            if len(words[i]) <= 0:\n",
    "                continue\n",
    "            temp = dict()\n",
    "            #labels.append(sentence_data[i][3])\n",
    "            if context:\n",
    "                if(sentence_length == 1):#only one word in the sentence\n",
    "                    if token:\n",
    "                        current_token = words[i].lower()\n",
    "                        temp.update({\"tok=\"+current_token:1})\n",
    "                    if caps:\n",
    "                        if len(words[i]) == 1:\n",
    "                            if words[i].isupper():\n",
    "                                temp.update({\"is_caps\":1})\n",
    "                        else:\n",
    "                            if words[i][0].isupper():\n",
    "                                temp.update({\"is_caps\":1})\n",
    "                    if w2v:\n",
    "                        try:\n",
    "                            current_wv = w2v_model_wv[words[i]]\n",
    "                            for k in range(len(current_wv)):\n",
    "                                temp.update({\"w2v_\"+ str(k) : current_wv[k]})\n",
    "                        except Exception as e:\n",
    "                            current_wv = []\n",
    "                            sentence_dict.update(temp)\n",
    "                            continue\n",
    "                elif i > 0 and i+1 < sentence_length:#middle words\n",
    "                    if token:\n",
    "                        prev_token = current_token\n",
    "                        current_token = next_token\n",
    "                        next_token = words[i+1].lower()\n",
    "                        temp.update({\"tok=\"+current_token:1, \"prev_tok=\"+prev_token:1, \"next_tok=\"+next_token:1})\n",
    "                    if caps:\n",
    "                        prev_is_caps = current_is_caps\n",
    "                        if prev_is_caps:\n",
    "                            temp.update({\"prev_is_caps\":1})\n",
    "                            current_is_caps = next_is_caps\n",
    "                        if current_is_caps:\n",
    "                            temp.update({\"is_caps\":1})\n",
    "                            if len(words[i+1]) == 1:\n",
    "                                if words[i+1].isupper():\n",
    "                                    next_is_caps = 1\n",
    "                                    temp.update({\"is_caps\":1})\n",
    "                                else:\n",
    "                                    next_is_caps = 0\n",
    "                            else:\n",
    "                                if len(words[i+1]) <= 0:\n",
    "                                    next_is_caps = 0\n",
    "                                    continue\n",
    "                                if words[i+1][0].isupper():\n",
    "                                    next_is_caps = 1\n",
    "                                    temp.update({\"next_is_caps\":1})\n",
    "                                else:\n",
    "                                    next_is_caps = 0\n",
    "                    if w2v:\n",
    "                        prev_wv = current_wv\n",
    "                        for k in range(len(prev_wv)):\n",
    "                            temp.update({\"prev_w2v_\" + str(k) : prev_wv[k]})\n",
    "                        current_wv = next_wv\n",
    "                        for k in range(len(current_wv)):\n",
    "                            temp.update({\"w2v_\" + str(k) : current_wv[k]})\n",
    "                        try:\n",
    "                            next_wv = w2v_model_wv[words[i+1]]\n",
    "                            for k in range(len(next_wv)):\n",
    "                                temp.update({\"next_w2v_\" + str(k) : next_wv[k]})\n",
    "                        except Exception as e:\n",
    "                            next_wv = []\n",
    "                            sentence_dict.update(temp)\n",
    "                            continue\n",
    "                elif i+1 == sentence_length:#last but one token\n",
    "                    if token:\n",
    "                        prev_token = current_token\n",
    "                        current_token = next_token\n",
    "                        temp.update({\"tok=\"+current_token:1, \"prev_tok=\"+prev_token:1})\n",
    "                    if caps:\n",
    "                        prev_is_caps = current_is_caps\n",
    "                        if prev_is_caps:\n",
    "                            temp.update({\"prev_is_caps\":1})\n",
    "                            current_is_caps = next_is_caps\n",
    "                        if current_is_caps:\n",
    "                            temp.update({\"is_caps\":1})\n",
    "                    if w2v:\n",
    "                        prev_wv = current_wv\n",
    "                        current_wv = next_wv\n",
    "                        for k in range(len(prev_wv)):\n",
    "                            temp.update({\"prev_w2v_\" + str(k) : prev_wv[k]})\n",
    "                        for k in range(len(current_wv)):\n",
    "                            temp.update({\"w2v_\" + str(k) : current_wv[k]})\n",
    "                else:#first token\n",
    "                    if token:\n",
    "                        current_token = words[i].lower()\n",
    "                        next_token = words[i+1].lower()\n",
    "                        temp.update({\"tok=\"+current_token:1, \"next_tok=\"+next_token:1})\n",
    "                    if caps:\n",
    "                        if words[i][0].isupper():\n",
    "                            current_is_caps = 1\n",
    "                            temp.update({\"is_caps\":1})\n",
    "                        else:\n",
    "                            current_is_caps = 0\n",
    "                            if len(words[i+1]) == 1:\n",
    "                                if words[i+1].isupper():\n",
    "                                    next_is_caps = 1\n",
    "                                    temp.update({\"next_is_caps\":1})\n",
    "                                else:\n",
    "                                    next_is_caps = 0\n",
    "                            else:\n",
    "                                if len(words[i+1]) <= 0:\n",
    "                                    next_is_caps = 0\n",
    "                                    continue\n",
    "                                if words[i+1][0].isupper():\n",
    "                                    next_is_caps = 1\n",
    "                                    temp.update({\"next_is_caps\":1})\n",
    "                                else:\n",
    "                                    next_is_caps = 0\n",
    "                    if w2v:\n",
    "                        try:\n",
    "                            current_wv = w2v_model_wv[words[i]]\n",
    "                            for k in range(len(current_wv)):\n",
    "                                temp.update({\"w2v_\" + str(k) : current_wv[k]})\n",
    "                        except Exception as e:\n",
    "                            current_wv = []\n",
    "                            #continue\n",
    "                        try:\n",
    "                            next_wv = w2v_model_wv[words[i+1]]\n",
    "                            for k in range(len(current_wv)):\n",
    "                                temp.update({\"next_w2v_\" + str(k) : next_wv[k]})\n",
    "                        except Exception as e:\n",
    "                            next_wv = []\n",
    "                            sentence_dict.update(temp)\n",
    "                            continue\n",
    "            else:\n",
    "                if token:\n",
    "                    current_token = words[i].lower()\n",
    "                    temp.update({\"tok=\"+current_token:1})\n",
    "                if caps:\n",
    "                    if len(words[i]) == 1:\n",
    "                        if words[i].isupper():\n",
    "                            temp.update({\"is_caps\":1})\n",
    "                    else:\n",
    "                        if words[i][0].isupper():\n",
    "                             temp.update({\"is_caps\":1})\n",
    "                if w2v:\n",
    "                    try:\n",
    "                        current_wv = w2v_model_wv[words[i]]\n",
    "                        for k in range(len(current_wv)):\n",
    "                            temp.update({\"w2v_\" + str(k) : current_wv[k]})\n",
    "                    except Exception as e:\n",
    "                        current_wv = []\n",
    "                        sentence_dict.update(temp)\n",
    "                        continue\n",
    "            sentence_dict.update(temp)\n",
    "        #print(temp)\n",
    "        #print()\n",
    "        list_of_dicts.append(sentence_dict)\n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 6105)\n",
      "0.682986489317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=100, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=100,\n",
       "     multi_class='ovr', penalty='l2', random_state=123, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(w2v_model_wv[\"Chicago\"])\n",
    "#print(\"Something\")\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "train_dicts = make_feature_dicts(X, w2v_model_wv, w2v=True, token=True, caps=False, context=True)\n",
    "vec = DictVectorizer()\n",
    "X_train_v = vec.fit_transform(train_dicts)\n",
    "\n",
    "print(X_train_v.shape)\n",
    "\n",
    "clf_linear_svc = LinearSVC(C=c, random_state=123, class_weight=cw, max_iter=itr)\n",
    "acc = cross_val_score(clf_linear_svc, X_train_v, Y,scoring=\"accuracy\", cv=cv)\n",
    "print(np.mean(acc))\n",
    "\n",
    "clf_linear_svc.fit(X_train_v, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "test_dicts = make_feature_dicts(testData, w2v_model_wv, w2v=True, token=True, caps=True, context=True)\n",
    "X_test_v = vec.transform(test_dicts)\n",
    "\n",
    "Y_pred = clf_linear_svc.predict(X_test_v)\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
